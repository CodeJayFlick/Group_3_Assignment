{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cd77ea-130f-488a-b61b-7ff5cf0035e4",
   "metadata": {},
   "source": [
    "# Assignment 2: News - Scraping for News Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb677e81-c542-46c7-a725-ffd08443996b",
   "metadata": {},
   "source": [
    "## Created by: Cody Franecki, Antonio Rosado, Frankmed Avegne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de5b18-c06d-4c61-83f9-1bc0a87bab44",
   "metadata": {},
   "source": [
    "## Professor Leonchuck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546d272-5e2e-4104-bba7-8a09eb2b8d19",
   "metadata": {},
   "source": [
    "## Web and Text Scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5ceb4-910e-4efb-9c7c-4ea33fe6276f",
   "metadata": {},
   "source": [
    "## 21 September, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c214c-f33a-4feb-a351-9ebbeae9b1f3",
   "metadata": {},
   "source": [
    "### Our group (Group 3) is tasked with scraping text of the author, date, and the body of text for text mining. The articles that we need to scrape is 5 articles, 4 about our main topic (Technology) and 1 sub-topic (Science). Each member is submitting 5 articles per person. The due date is set for September 30th (This monday), although, he did say he would change the due date to wendsday, October 2nd at the time of this text being created. Okay let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7bd22-46be-4946-ad22-4eedeb951ca5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14af8bbe-2116-4675-8cc6-873f2b9183d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f0997-3157-410a-bf62-72c02dc9eef8",
   "metadata": {},
   "source": [
    "### Article 1 (The Tech Crash Course That Trains US Diplomats to Spot Threats (Technology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c6f53a5-d894-449a-86a1-44846159c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Cody\n",
      "[nltk_data]     Franecki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Cody\n",
      "[nltk_data]     Franecki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Cody\n",
      "[nltk_data]     Franecki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm doing some commands here to get the natural language toolkit to work.\n",
    "# Including the use of stopwords.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f124c3e5-88d2-4930-80af-a7de234ac134",
   "metadata": {},
   "outputs": [],
   "source": [
    "Article_1 = r\"C:\\Users\\Cody Franecki\\OneDrive\\Documents\\Articles_For_Web_Scraping\\0301_Tech.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d1ccf7-6f5f-4ebf-b8b3-fc8662b1740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the first article to be used for text scraping\n",
    "with open(Article_1, 'r', encoding = 'utf-8') as file:\n",
    "    article_1_content = file.read()\n",
    "\n",
    "soup = bs(article_1_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236903fd-5400-41dd-86ab-6be35c091f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_1_content[:1000]) # Gathers the first 1000 characters for the text\n",
    "\n",
    "# Here, I printed all meta tags to see what would be available to help locate tags\n",
    "for meta in soup.find_all('meta'):\n",
    "    print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ddd21-f770-4f7f-89b3-69772450bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all information according to the credentials of the assignment\n",
    "author_tag = soup.find('meta', {'property': 'article:author'})\n",
    "author = author_tag['content']\n",
    "\n",
    "publisher = \"WIRED\"\n",
    "\n",
    "date_tag = soup.find('meta', {'property': 'article:published_time'})\n",
    "date = date_tag['content']\n",
    "\n",
    "body_div = soup.find('div', {'class': 'body__inner-container'})\n",
    "body = body_div.get_text()\n",
    "\n",
    "# Prints Information about the article\n",
    "print(f\"Author: {author}\")\n",
    "print(f\"Publisher: {publisher}\")\n",
    "print(f\"Date Published: {date}\")\n",
    "print(f\"Body Length: {body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ffb725-a5e4-404b-aa2a-8f47bb60a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count: 668\n",
      "Sentence Count: 12\n",
      "Unique Words: 247\n",
      "\n",
      "Top 10 Common Words\n",
      "us: 12\n",
      "cyber: 6\n",
      "fick: 6\n",
      "diplomacy: 5\n",
      "digital: 5\n",
      "state: 4\n",
      "diplomats: 4\n",
      "issues: 4\n",
      "training: 4\n",
      "tech: 4\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing text inside of the body\n",
    "words = word_tokenize(body)\n",
    "sentences = sent_tokenize(body)\n",
    "\n",
    "# Removing Stopwords\n",
    "stops = list(stopwords.words('english'))\n",
    "filtered_words = [] # temp variable for filtering data for lower or uppercase words\n",
    "for word in words:\n",
    "    if word.isalnum() and word.lower() not in stops:\n",
    "        filtered_words.append(word.lower())\n",
    "\n",
    "# Calculating frequency of words\n",
    "frequency_distribution = FreqDist(filtered_words)\n",
    "\n",
    "# Printing total number of words and sentences within the body\n",
    "print(f\"Word Count: {len(words)}\")\n",
    "print(f\"Sentence Count: {len(sentences)}\")\n",
    "print(f\"Unique Words: {len(set(filtered_words))}\")\n",
    "\n",
    "# Not sure if this was relevent, but I figured that I could do this for fun\n",
    "print(\"\\nTop 10 Common Words\")\n",
    "for word, count in frequency_distribution.most_common(10):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1c598-08ab-47d0-a92f-23ab372b98ac",
   "metadata": {},
   "source": [
    "### Article 2: Codeminer42 Dev Weekly #23 - The Miners (Technology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1bb8f14-a36e-46e6-8b89-29835c58f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before, Use all the libraries defined in the top cell, then collecting\n",
    "# data for text scraping\n",
    "Article_2 = r\"C:\\Users\\Cody Franecki\\OneDrive\\Documents\\Articles_For_Web_Scraping\\0302_Tech.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2476696-24c2-4450-ab33-e893c5883bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to open the Second Article for Text Mining\n",
    "with open(Article_2, 'r', encoding = 'utf-8') as file:\n",
    "    article_2_content = file.read()\n",
    "\n",
    "soup = bs(article_2_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a732c-e1b4-42cb-bd0d-a57adb453c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_2_content[:1000]) # Gathers the first 1000 characters for the text\n",
    "\n",
    "# Here, I printed all meta tags to see what would be available to help locate tags\n",
    "for meta in soup.find_all('meta'):\n",
    "    print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bdc5cc5-7f5d-4d1b-80e0-45ca011c374c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Extracting all information according to the credentials of the assignment\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Note: We could not find a way for this particular article to use beautiful\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# soup. Instead, we had opted to using json to extract the data for the author tag\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m author_tag \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maioseo-schema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m)\n\u001b[0;32m      6\u001b[0m author \u001b[38;5;241m=\u001b[39m author_tag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@graph\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#author = \"Gabriel Quaresma\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Extracting all information according to the credentials of the assignment\n",
    "# Note: We could not find a way for this particular article to use beautiful\n",
    "# soup. Instead, we had opted to using json to extract the data for the author tag\n",
    "#author_tag = json.loads(soup.find('script', {'class': 'aioseo-schema'}).string)\n",
    "#author = author_tag['@graph'][3]['name']\n",
    "#author = \"Gabriel Quaresma\"\n",
    "\n",
    "publisher_tag = soup.find('meta', {'property': 'og:site_name'})\n",
    "publisher = publisher_tag['content']\n",
    "#publisher = \"CodeMiner42\"\n",
    "\n",
    "date_tag = soup.find('meta', {'property': 'article:published_time'})\n",
    "date = date_tag['content']\n",
    "\n",
    "body_div = soup.find('div', {'class': 'entry-content'})\n",
    "body = body_div.get_text()\n",
    "\n",
    "# Prints Information about the article\n",
    "print(f\"Author: {author}\")\n",
    "print(f\"Publisher: {publisher}\")\n",
    "print(f\"Date Published: {date}\")\n",
    "print(f\"Body Length: {len(body)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa5145-8e73-45ba-9eea-5042e318301d",
   "metadata": {},
   "source": [
    "## The team at this point believed the process of defining the artiles would be much easier to define within the same cell blocks instead of separately:\n",
    "## Article 3: A Mercedes-Benz EV Fire May Cloud Korea's Electric Car Transition (Technology) (0303)\n",
    "## Article 4: Everything I Expect to See at Connect 2024 (Technology) (0304)\n",
    "## Article 5: Where Do We Search For the Fundamental Stuff of Life (0305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb9f21-200c-41b0-a760-1afa8fcec520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Pathway for article 3\n",
    "Article_3 = r\"C:\\Users\\Cody Franecki\\OneDrive\\Documents\\Articles_For_Web_Scraping\\0303_Tech.html\"\n",
    "Article_4 = r\"C:\\Users\\Cody Franecki\\OneDrive\\Documents\\Articles_For_Web_Scraping\\0304_Tech.html\"\n",
    "Article_5 = r\"C:\\Users\\Cody Franecki\\OneDrive\\Documents\\Articles_For_Web_Scraping\\0305_Science.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9296d422-5ed6-4992-9d47-52ba3bafab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, opening the third article for text mining\n",
    "with open(Article_3, 'r', encoding = 'utf-8') as file:\n",
    "    article_3_content = file.read()\n",
    "\n",
    "soup = bs(article_3_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c1a3372-312d-4a5e-8fe9-ff2907f3ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><title>A Mercedes-Benz EV Fire May Cloud Korea’s Electric Car Transition - Bloomberg</title><link rel=\"icon\" type=\"image/png\" href=\"https://www.bloomberg.com/favicon-black.png\"/><link rel=\"canonical\" href=\"https://www.bloomberg.com/news/articles/2024-09-22/a-mercedes-benz-fire-may-cloud-korea-s-ev-transition-hyperdrive\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, viewport-fit=cover\"/><meta name=\"apple-itunes-app\" content=\"app-id=281941097\"/><meta name=\"robots\" content=\"max-image-preview:large\"/><meta name=\"description\" content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.\"/><meta property=\"og:description\" content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fea\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width\" name=\"viewport\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1, viewport-fit=cover\" name=\"viewport\"/>\n",
      "<meta content=\"app-id=281941097\" name=\"apple-itunes-app\"/>\n",
      "<meta content=\"max-image-preview:large\" name=\"robots\"/>\n",
      "<meta content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.\" name=\"description\"/>\n",
      "<meta content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.\" property=\"og:description\"/>\n",
      "<meta content=\"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iYtTpNQ4ZRnA/v0/1200x800.jpg\" property=\"og:image\"/>\n",
      "<meta content=\"Bloomberg.com\" property=\"og:site_name\"/>\n",
      "<meta content=\"A Mercedes-Benz Fire May Cloud Korea’s EV Transition\" property=\"og:title\"/>\n",
      "<meta content=\"article\" property=\"og:type\"/>\n",
      "<meta content=\"https://www.bloomberg.com/news/articles/2024-09-22/a-mercedes-benz-fire-may-cloud-korea-s-ev-transition-hyperdrive\" property=\"og:url\"/>\n",
      "<meta content=\"summary_large_image\" name=\"twitter:card\"/>\n",
      "<meta content=\"@technology\" name=\"twitter:site\"/>\n",
      "<meta content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.\" name=\"twitter:description\"/>\n",
      "<meta content=\"A Mercedes-Benz Fire May Cloud Korea’s EV Transition\" name=\"twitter:title\"/>\n",
      "<meta content=\"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iYtTpNQ4ZRnA/v0/1200x800.jpg\" name=\"twitter:image\"/>\n",
      "<meta content=\"2\" name=\"twitter:tile:template:testing\"/>\n",
      "<meta content=\"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iYtTpNQ4ZRnA/v0/1200x800.jpg\" name=\"twitter:tile:image\"/>\n",
      "<meta content=\"A Mercedes-Benz Fire May Cloud Korea’s EV Transition\" name=\"twitter:tile:image:alt\"/>\n",
      "<meta content=\"A Mercedes-Benz EV Fire May Cloud Korea’s Electric Car Transition\" name=\"parsely-title\"/>\n",
      "<meta content=\"https://www.bloomberg.com/news/articles/2024-09-22/a-mercedes-benz-fire-may-cloud-korea-s-ev-transition-hyperdrive\" name=\"parsely-link\"/>\n",
      "<meta content=\"post\" name=\"parsely-type\"/>\n",
      "<meta content=\"https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iYtTpNQ4ZRnA/v0/1200x800.jpg\" name=\"parsely-image-url\"/>\n",
      "<meta content=\"2024-09-22T23:00:00.000Z\" name=\"parsely-pub-date\"/>\n",
      "<meta content=\"technology\" name=\"parsely-section\"/>\n",
      "<meta content=\"Electric Vehicles,Automotive,Cities,Incheon,Government,Regulation,Media,Investing,Secondary Brand: technology,Secondary Brand: business,Franchise: hyperdrive,Region: Global,Page: article\" name=\"parsely-tags\"/>\n",
      "<meta content=\"SK05EDT0AFB400\" name=\"parsely-post-id\"/>\n",
      "<meta content=\"Heesu Lee\" name=\"parsely-author\"/>\n",
      "<meta content=\"bloomberg://www.bloomberg.com/news/articles/2024-09-22/a-mercedes-benz-fire-may-cloud-korea-s-ev-transition-hyperdrive?utm_medium=applink&amp;utm_source=facebook\" property=\"al:android:url\"/>\n",
      "<meta content=\"com.bloomberg.android.plus\" property=\"al:android:package\"/>\n",
      "<meta content=\"Bloomberg\" property=\"al:android:app_name\"/>\n",
      "<meta content=\"2024-09-22T23:00:00.000Z\" name=\"iso-8601-publish-date\"/>\n",
      "<meta content=\"006d83fbec521fbf8bf1d776f2ca39ae\" name=\"checksum\"/>\n",
      "<meta content=\"2024-09-22T23:00:00.000Z\" name=\"validatedAt\"/>\n",
      "<meta content=\"false\" property=\"article:opinion\"/>\n",
      "<meta content=\"metered\" property=\"article:content_tier\"/>\n",
      "<meta content=\"A Mercedes-Benz EV that burst into flames in a South Korean city has fueled public fear over the safety of battery-powered cars in recent months\" name=\"fb:status\"/>\n",
      "<meta content=\"\" name=\"lotame-bbg-category\"/>\n",
      "<meta content=\"electric-vehicles,automotive,cities,government,infrastructure,transportation\" name=\"lotame-bbg-topic\"/>\n",
      "<meta content=\"Heesu Lee\" name=\"sailthru.author\"/>\n",
      "<meta content=\"2024-09-22T23:00:00.000Z\" name=\"sailthru.date\"/>\n",
      "<meta content=\"A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.\" name=\"sailthru.description\"/>\n",
      "<meta content=\"A Mercedes-Benz Fire May Cloud Korea’s EV Transition\" name=\"sailthru.headline\"/>\n",
      "<meta content=\"Electric Vehicles,Automotive,Cities,Incheon,Government,Regulation,Media,Investing,technology,business,hyperdrive\" name=\"keywords\"/>\n",
      "<meta content=\"Electric Vehicles,Automotive,Cities,Incheon,Government,Regulation,Media,Investing,technology,business,hyperdrive\" name=\"sailthru.tags\"/>\n",
      "<meta content=\"A Mercedes-Benz EV Fire May Cloud Korea’s Electric Car Transition\" name=\"sailthru.title\"/>\n",
      "<meta content=\"true\" name=\"will-have-content-metadata\"/>\n",
      "<meta content=\"20\" name=\"next-head-count\"/>\n",
      "<meta content=\"telephone=no\" name=\"format-detection\"/>\n"
     ]
    }
   ],
   "source": [
    "# Now, retrieving the Metadata needed for the article to find the meta tags associated with the article\n",
    "print(article_3_content[:1000])\n",
    "\n",
    "for meta in soup.find_all('meta'):\n",
    "    print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc6a4595-779b-4b37-9864-1ad02f703cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Heesu Lee\n",
      "Publisher: Bloomberg.com\n",
      "Publication Date: 2024-09-22T23:00:00.000Z\n",
      "Body of Text: A Mercedes-Benz electric vehicle that burst into flames in the South Korean city of Incheon has fueled public fear over the safety of battery-powered cars in recent months.The incident saw 23 people hospitalized for smoke inhalation and left more than 200 families homeless for weeks. Authorities said it took more than eight hours to extinguish the blaze, which was caused after an unplugged electric sedan exploded in an underground apartment carpark in July.\n"
     ]
    }
   ],
   "source": [
    "# Author Tag (Article 3)\n",
    "author_tag = soup.find('meta', {'name': 'parsely-author'})\n",
    "author = author_tag['content']\n",
    "\n",
    "publisher_tag = soup.find('meta', {'property': 'og:site_name'})\n",
    "publisher = publisher_tag['content']\n",
    "\n",
    "date_tag = soup.find('meta', {'name': 'parsely-pub-date'})\n",
    "date = date_tag['content']\n",
    "\n",
    "body_div = soup.find('div', {'class': 'body-content'})\n",
    "body = body_div.get_text()\n",
    "\n",
    "print(f'Author: {author}')\n",
    "print(f'Publisher: {publisher}')\n",
    "print(f'Publication Date: {date}')\n",
    "print(f'Body of Text: {body}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab45e7-4e61-4b21-8639-1e9e54bf6f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
